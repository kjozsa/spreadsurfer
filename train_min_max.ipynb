{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset: 201839 rows\n",
      "min dataset: 69536\n",
      "max dataset: 70401\n"
     ]
    },
    {
     "data": {
      "text/plain": "count    69536.000000\nmean         0.599530\nstd          1.025531\nmin          0.000000\n25%          0.000000\n50%          0.220000\n75%          0.760000\nmax         30.220000\nName: last_price_delta_since_stabilized, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "count    70401.000000\nmean        -0.583757\nstd          0.997632\nmin        -20.960000\n25%         -0.740000\n50%         -0.210000\n75%          0.000000\nmax          0.000000\nName: last_price_delta_since_stabilized, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet('./data')\n",
    "\n",
    "## filters\n",
    "# df = df[df['stabilized_spread'] < 10]  # nem tul nagy spread\n",
    "# df = df[df['stabilized_spread'] > 0.3]  # nem tul kis spread\n",
    "\n",
    "print(f'total dataset: {len(df)} rows')\n",
    "\n",
    "for col in df.columns:\n",
    "    if 'nr_trades' in col or 'price_delta' in col and not col.startswith('last'):\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    # if 'nr_trades' in col:\n",
    "    #     df.drop(col, axis=1, inplace=True)\n",
    "    if 'past' in col:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    if '_spread' == col[1:]:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    pass\n",
    "\n",
    "df_min = df[df.wave_direction == 'min'].copy()\n",
    "df_max = df[df.wave_direction == 'max'].copy()\n",
    "\n",
    "df.drop('wave_direction', axis=1, inplace=True)\n",
    "df_min.drop('wave_direction', axis=1, inplace=True)\n",
    "df_max.drop('wave_direction', axis=1, inplace=True)\n",
    "print(f'min dataset: {len(df_min)}')\n",
    "print(f'max dataset: {len(df_max)}')\n",
    "\n",
    "df_min.sort_index(axis=1, inplace=True)\n",
    "df_max.sort_index(axis=1, inplace=True)\n",
    "\n",
    "display(df_min.last_price_delta_since_stabilized.describe())\n",
    "display(df_max.last_price_delta_since_stabilized.describe())\n",
    "\n",
    "# display(df_max)\n",
    "\n",
    "## df_max.last_price_delta_since_stabilized = df_max.last_price_delta_since_stabilized * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "last_price_delta_since_stabilized    1000.000000\nstabilized_gasp                        40.140500\nstabilized_at_ms                       33.182801\nstabilized_spread                      10.520160\n2_amount_mean                           1.640186\n1_amount_mean                           1.035427\n3_amount_mean                           0.664238\n0_amount_mean                          -1.284374\n4_amount_mean                          -1.629724\nstabilized_amount_mean                 -2.212604\nName: last_price_delta_since_stabilized, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = df.corr().last_price_delta_since_stabilized * 1000\n",
    "display(a.sort_values(axis=0, ascending=False))\n",
    "\n",
    "# a = df_min.corr().last_price_delta_since_stabilized * 1000\n",
    "# display(a.sort_values(axis=0, ascending=False))\n",
    "#\n",
    "# a = df_max.corr().last_price_delta_since_stabilized * 1000\n",
    "# display(a.sort_values(axis=0, ascending=False))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "'MAPE: 0.12600981684257384'"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spreadsurfer.price_engine import FeatureEngineer\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def train(df, loss_function):\n",
    "    # model = CatBoostRegressor(learning_rate=0.01, depth=7, loss_function=loss_function, random_state=0, verbose=False, iterations=1500)\n",
    "    model = CatBoostRegressor(learning_rate=0.15, depth=6, loss_function=loss_function, random_state=0, verbose=False)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', FeatureEngineer()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    df = df.copy()\n",
    "    y = df['last_price_delta_since_stabilized']\n",
    "    X = df.drop('last_price_delta_since_stabilized', axis=1)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    score = pipeline.score(X_valid, y_valid)\n",
    "    display(f'{loss_function}: {score}')\n",
    "    return model, score\n",
    "\n",
    "\n",
    "min_model, min_score = train(df, loss_function='MAPE')\n",
    "# max_model, max_score = train(df_max, loss_function='MAPE')\n",
    "# min_model, min_score = train(df, loss_function='RMSE')\n",
    "# max_model, max_score = train(df_max, loss_function='RMSE')\n",
    "\n",
    "# min_model, min_score = train(df_min, loss_function='Poisson') # 0.12\n",
    "# max_model, max_score = train(df, loss_function='Poisson') # 0.14\n",
    "\n",
    "# min_model, min_score = train(df_min, loss_function='Huber:delta=0.4')\n",
    "# max_model, max_score = train(df, loss_function='Huber:delta=0.4')\n",
    "\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.8')\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.7')\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.6')\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.5')\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.4')\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.3')\n",
    "# max_model, max_score = train(df, loss_function='Quantile:alpha=0.2')\n",
    "\n",
    "# max_model, max_score = train(df_max, loss_function='Quantile:alpha=0.7')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "'Quantile:alpha=0.811: 0.017096799918225103'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Quantile:alpha=0.178: 0.003792171935041111'"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_model, min_score = train(df, loss_function='Quantile:alpha=0.811')\n",
    "max_model, max_score = train(df, loss_function='Quantile:alpha=0.178') # 0.0038\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "from spreadsurfer import now_isoformat\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    min_model.save_model(f'./models/{now_isoformat()}-mape-score-{1000 * round(min_score, 3)}.cat')\n",
    "    # max_model.save_model(f'./models/{now_isoformat()}-quantile0178-score-{1000 * round(max_score, 3)}.cat')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected:  -0.25\n",
      "predict:  -0.33381900802663705\n",
      "\n",
      "expected:  0.64\n",
      "predict:  0.3336713274390162\n",
      "\n",
      "expected:  0.55\n",
      "predict:  0.4827536632059254\n",
      "\n",
      "expected:  -0.5\n",
      "predict:  -0.31529032645272353\n",
      "\n",
      "expected:  -0.23\n",
      "predict:  -0.5161163142562414\n",
      "\n",
      "expected:  -1.59\n",
      "predict:  -0.3551902269828745\n",
      "\n",
      "expected:  1.14\n",
      "predict:  1.1380419517450282\n",
      "\n",
      "expected:  0.94\n",
      "predict:  0.8185788298481572\n",
      "\n",
      "expected:  -0.54\n",
      "predict:  -0.6295173418783049\n",
      "\n",
      "expected:  -0.21\n",
      "predict:  -0.38243273635497005\n",
      "\n",
      "expected:  -0.33\n",
      "predict:  -0.21370283745824653\n",
      "\n",
      "expected:  0.21\n",
      "predict:  1.4007142361503633\n",
      "\n",
      "expected:  -0.43\n",
      "predict:  -0.48145900839721256\n",
      "\n",
      "expected:  -1.01\n",
      "predict:  -0.43318889911389374\n",
      "\n",
      "expected:  -0.2\n",
      "predict:  -0.5021814621222135\n",
      "\n",
      "expected:  3.18\n",
      "predict:  0.1477227994364838\n",
      "\n",
      "expected:  -0.3\n",
      "predict:  -0.22451048839569404\n",
      "\n",
      "expected:  0.92\n",
      "predict:  0.009160082248520402\n",
      "\n",
      "expected:  0.27\n",
      "predict:  0.017790864704376037\n",
      "\n",
      "expected:  1.73\n",
      "predict:  -0.4107362426920435\n",
      "\n",
      "expected:  -0.39\n",
      "predict:  -0.22475383992859557\n",
      "\n",
      "expected:  -0.27\n",
      "predict:  -0.2652082855141976\n",
      "\n",
      "expected:  -0.27\n",
      "predict:  -0.5084277135190278\n",
      "\n",
      "expected:  -2.4\n",
      "predict:  -0.6980657569553759\n",
      "\n",
      "expected:  0.39\n",
      "predict:  2.0579586777548355\n",
      "\n",
      "expected:  0.48\n",
      "predict:  0.06811366198797611\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'MAE: 0.15387618899734767'"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = min_model\n",
    "\n",
    "with open(\"neverseen.log\",\"r\") as f:\n",
    "    input_from_log = ''.join([x for x in f.readlines() if 'collected' in x][-100:])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', FeatureEngineer()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "mae = 0\n",
    "count = 0\n",
    "for line in input_from_log.split('\\n'):\n",
    "    if not line: continue\n",
    "    count += 1\n",
    "    json = '{' + line.split('{')[1]\n",
    "    json = json.replace('nan', '0')\n",
    "    sample = pd.DataFrame([eval(json)])\n",
    "    if sample.wave_direction[0] not in ['min', 'max']: continue\n",
    "\n",
    "    real = sample.last_price_delta_since_stabilized[0]\n",
    "    if abs(real) < 0.2: continue\n",
    "    sample.drop('last_price_delta_since_stabilized', axis=1, inplace=True)\n",
    "\n",
    "    sample.loc[sample['wave_direction'] == 'min', 'wave_direction'] = 1\n",
    "    sample.loc[sample['wave_direction'] == 'max', 'wave_direction'] = -1\n",
    "    sample = sample.astype({\"wave_direction\": 'float64'})\n",
    "\n",
    "    # if sample['wave_direction'][0] != (1 if min else -1):\n",
    "    #     continue\n",
    "\n",
    "    print('expected: ', real)\n",
    "    guess = model.predict(sample)[0]\n",
    "    guess *= 3.5\n",
    "    print('predict: ', guess)\n",
    "    mae += abs(real - guess)\n",
    "    print()\n",
    "display(f'MAE: {mae / count}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
